{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10091648,
          "sourceType": "datasetVersion",
          "datasetId": 6222908
        },
        {
          "sourceId": 10095448,
          "sourceType": "datasetVersion",
          "datasetId": 6225754
        },
        {
          "sourceId": 10095462,
          "sourceType": "datasetVersion",
          "datasetId": 6225767
        },
        {
          "sourceId": 10096915,
          "sourceType": "datasetVersion",
          "datasetId": 6226946
        }
      ],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:33:57.539170Z",
          "iopub.execute_input": "2024-12-04T10:33:57.539545Z",
          "iopub.status.idle": "2024-12-04T10:33:57.555976Z",
          "shell.execute_reply.started": "2024-12-04T10:33:57.539515Z",
          "shell.execute_reply": "2024-12-04T10:33:57.555162Z"
        },
        "id": "VBim8jHA2ejM",
        "outputId": "bf466cfd-8aef-4808-a6bb-7915b34fe3aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/test123/samsum-test.csv\n/kaggle/input/assignment-no-4nlp/samsum-test.csv\n/kaggle/input/prediction/samsum-test-predictions.csv\n/kaggle/input/1234test/samsum-train.csv\n/kaggle/input/1234test/samsum-test.csv\n/kaggle/input/1234test/samsum-validation.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LayerNormalization, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.train import Checkpoint, CheckpointManager\n",
        "from tensorflow.keras.metrics import Mean"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:33:57.557463Z",
          "iopub.execute_input": "2024-12-04T10:33:57.557795Z",
          "iopub.status.idle": "2024-12-04T10:33:57.563479Z",
          "shell.execute_reply.started": "2024-12-04T10:33:57.557755Z",
          "shell.execute_reply": "2024-12-04T10:33:57.562568Z"
        },
        "id": "jo_-l13R2ejN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ppreprocessing"
      ],
      "metadata": {
        "id": "Rp4S6ti52ejN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/1234test/samsum-train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:33:57.609190Z",
          "iopub.execute_input": "2024-12-04T10:33:57.610000Z",
          "iopub.status.idle": "2024-12-04T10:33:57.756518Z",
          "shell.execute_reply.started": "2024-12-04T10:33:57.609972Z",
          "shell.execute_reply": "2024-12-04T10:33:57.755279Z"
        },
        "id": "3UZf9uRK2ejO",
        "outputId": "7ea67b56-245f-4542-9632-42c70aa8e862"
      },
      "outputs": [
        {
          "execution_count": 130,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         id                                           dialogue  \\\n0  13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n1  13728867  Olivia: Who are you voting for in this electio...   \n2  13681000  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n3  13730747  Edward: Rachel, I think I'm in ove with Bella....   \n4  13728094  Sam: hey  overheard rick say something\\r\\nSam:...   \n\n                                             summary  \n0  Amanda baked cookies and will bring Jerry some...  \n1  Olivia and Olivier are voting for liberals in ...  \n2  Kim may try the pomodoro technique recommended...  \n3  Edward thinks he is in love with Bella. Rachel...  \n4  Sam is confused, because he overheard Rick com...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dialogue</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13818513</td>\n      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n      <td>Amanda baked cookies and will bring Jerry some...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13728867</td>\n      <td>Olivia: Who are you voting for in this electio...</td>\n      <td>Olivia and Olivier are voting for liberals in ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13681000</td>\n      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n      <td>Kim may try the pomodoro technique recommended...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13730747</td>\n      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n      <td>Edward thinks he is in love with Bella. Rachel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13728094</td>\n      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n      <td>Sam is confused, because he overheard Rick com...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue = df['dialogue'].astype(str)\n",
        "summary = df['summary'].astype(str)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:33:57.757999Z",
          "iopub.execute_input": "2024-12-04T10:33:57.758293Z",
          "iopub.status.idle": "2024-12-04T10:33:57.763946Z",
          "shell.execute_reply.started": "2024-12-04T10:33:57.758264Z",
          "shell.execute_reply": "2024-12-04T10:33:57.763171Z"
        },
        "id": "5pHHnJJM2ejO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def add_tokens(x):\n",
        "    return '<START> ' + x + ' <END>'\n",
        "\n",
        "summary = summary.apply(add_tokens)\n",
        "print(\"Summary after adding tokens:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:33:57.764942Z",
          "iopub.execute_input": "2024-12-04T10:33:57.765224Z",
          "iopub.status.idle": "2024-12-04T10:33:57.780155Z",
          "shell.execute_reply.started": "2024-12-04T10:33:57.765198Z",
          "shell.execute_reply": "2024-12-04T10:33:57.779470Z"
        },
        "id": "zdL9VbUC2ejO",
        "outputId": "725b380c-c0a9-4698-a609-8ef5dd7efc02"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Summary after adding tokens:\n0        <START> Amanda baked cookies and will bring Je...\n1        <START> Olivia and Olivier are voting for libe...\n2        <START> Kim may try the pomodoro technique rec...\n3        <START> Edward thinks he is in love with Bella...\n4        <START> Sam is confused, because he overheard ...\n                               ...                        \n14727    <START> Romeo is trying to get Greta to add hi...\n14728    <START> Theresa is at work. She gets free food...\n14729    <START> Japan is going to hunt whales again. I...\n14730    <START> Celia couldn't make it to the afternoo...\n14731    <START> Georgia and Juliette are looking for a...\nName: summary, Length: 14732, dtype: object\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'\n",
        "\n",
        "dia_tokenizer = Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = Tokenizer(filters=filters, oov_token=oov_token)\n",
        "\n",
        "dia_tokenizer.fit_on_texts(dialogue)\n",
        "summary_tokenizer.fit_on_texts(summary)\n",
        "\n",
        "inputs = dia_tokenizer.texts_to_sequences(dialogue)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:33:57.781831Z",
          "iopub.execute_input": "2024-12-04T10:33:57.782083Z",
          "iopub.status.idle": "2024-12-04T10:34:00.149705Z",
          "shell.execute_reply.started": "2024-12-04T10:33:57.782056Z",
          "shell.execute_reply": "2024-12-04T10:34:00.148733Z"
        },
        "id": "zehq5Fzj2ejO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.texts_to_sequences([\"Hello world\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.150740Z",
          "iopub.execute_input": "2024-12-04T10:34:00.151012Z",
          "iopub.status.idle": "2024-12-04T10:34:00.156832Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.150984Z",
          "shell.execute_reply": "2024-12-04T10:34:00.155944Z"
        },
        "id": "ttatQzRg2ejO",
        "outputId": "f44d9685-1591-4d27-bcb5-83de8c1003d5"
      },
      "outputs": [
        {
          "execution_count": 134,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[[8416, 1267]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.sequences_to_texts([[8416, 1267]])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.158135Z",
          "iopub.execute_input": "2024-12-04T10:34:00.158483Z",
          "iopub.status.idle": "2024-12-04T10:34:00.170343Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.158443Z",
          "shell.execute_reply": "2024-12-04T10:34:00.169525Z"
        },
        "id": "Y5kiuyHe2ejP",
        "outputId": "9ee5e992-7514-41bb-b849-90225a726f47"
      },
      "outputs": [
        {
          "execution_count": 135,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['hello world']"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_vocab_size = len(dia_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.171414Z",
          "iopub.execute_input": "2024-12-04T10:34:00.171766Z",
          "iopub.status.idle": "2024-12-04T10:34:00.181841Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.171727Z",
          "shell.execute_reply": "2024-12-04T10:34:00.181127Z"
        },
        "id": "rPgjH23P2ejP",
        "outputId": "a9ca6558-e861-48be-eb29-355280ce1be2"
      },
      "outputs": [
        {
          "execution_count": 136,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(38359, 17604)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dia_lengths = []\n",
        "summary_lengths = []\n",
        "\n",
        "for n,s in zip(dialogue, summary):\n",
        "    dia_lengths.append(len(n))\n",
        "    summary_lengths.append(len(s))\n",
        "\n",
        "\n",
        "\n",
        "dia_lengths = pd.Series(dia_lengths)\n",
        "summary_lengths = pd.Series(summary_lengths)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.182659Z",
          "iopub.execute_input": "2024-12-04T10:34:00.182944Z",
          "iopub.status.idle": "2024-12-04T10:34:00.211469Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.182918Z",
          "shell.execute_reply": "2024-12-04T10:34:00.210608Z"
        },
        "id": "Ad2ay0W_2ejP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dia_lengths.describe(),summary_lengths.describe()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.212467Z",
          "iopub.execute_input": "2024-12-04T10:34:00.212788Z",
          "iopub.status.idle": "2024-12-04T10:34:00.229678Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.212757Z",
          "shell.execute_reply": "2024-12-04T10:34:00.228920Z"
        },
        "id": "goMQMcNM2ejP",
        "outputId": "4961115c-dd1f-43a6-8e30-df885b40b56d"
      },
      "outputs": [
        {
          "execution_count": 138,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(count    14732.000000\n mean       511.183818\n std        402.621178\n min          3.000000\n 25%        216.000000\n 50%        401.000000\n 75%        694.000000\n max       5492.000000\n dtype: float64,\n count    14732.000000\n mean       124.134673\n std         60.892471\n min         17.000000\n 25%         77.000000\n 50%        110.000000\n 75%        158.000000\n max        314.000000\n dtype: float64)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_maxlen =700\n",
        "decoder_maxlen = 160"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.232528Z",
          "iopub.execute_input": "2024-12-04T10:34:00.232840Z",
          "iopub.status.idle": "2024-12-04T10:34:00.236660Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.232814Z",
          "shell.execute_reply": "2024-12-04T10:34:00.235928Z"
        },
        "id": "OKuKikZj2ejP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "targets = pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.237726Z",
          "iopub.execute_input": "2024-12-04T10:34:00.237976Z",
          "iopub.status.idle": "2024-12-04T10:34:00.385852Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.237951Z",
          "shell.execute_reply": "2024-12-04T10:34:00.385156Z"
        },
        "id": "7dg4rTJm2ejP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.cast(inputs, dtype=tf.int32)\n",
        "targets = tf.cast(targets, dtype=tf.int32)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.386787Z",
          "iopub.execute_input": "2024-12-04T10:34:00.387021Z",
          "iopub.status.idle": "2024-12-04T10:34:00.446838Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.386997Z",
          "shell.execute_reply": "2024-12-04T10:34:00.446136Z"
        },
        "id": "ovfxJLn52ejP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.448031Z",
          "iopub.execute_input": "2024-12-04T10:34:00.448400Z",
          "iopub.status.idle": "2024-12-04T10:34:00.452753Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.448360Z",
          "shell.execute_reply": "2024-12-04T10:34:00.451754Z"
        },
        "id": "n58joyMK2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.453743Z",
          "iopub.execute_input": "2024-12-04T10:34:00.453986Z",
          "iopub.status.idle": "2024-12-04T10:34:00.474000Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.453962Z",
          "shell.execute_reply": "2024-12-04T10:34:00.473185Z"
        },
        "id": "cT6COmXY2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for inputs , targets in enumerate(ds):\n",
        "    print(inputs)\n",
        "    print(targets)\n",
        "    count+=1\n",
        "\n",
        "    if count > 2:\n",
        "        break"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.474977Z",
          "iopub.execute_input": "2024-12-04T10:34:00.475236Z",
          "iopub.status.idle": "2024-12-04T10:34:00.531431Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.475210Z",
          "shell.execute_reply": "2024-12-04T10:34:00.530553Z"
        },
        "id": "Mv3KmjnH2ejQ",
        "outputId": "38e989bb-741b-4dc2-e075-56f772169ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "0\n(<tf.Tensor: shape=(64, 700), dtype=int32, numpy=\narray([[1561,  131,    4, ...,    0,    0,    0],\n       [  94,  232,   59, ...,    0,    0,    0],\n       [5462,   16,  117, ...,    0,    0,    0],\n       ...,\n       [ 280,   26,    4, ...,    0,    0,    0],\n       [3430,   54,  101, ...,    0,    0,    0],\n       [ 246,   26,    4, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(64, 160), dtype=int32, numpy=\narray([[    2,  1518,   158, ...,     0,     0,     0],\n       [    2,    69,  1020, ...,     0,     0,     0],\n       [    2, 16681,     6, ...,     0,     0,     0],\n       ...,\n       [    2,   248,   552, ...,     0,     0,     0],\n       [    2,  9539,     6, ...,     0,     0,     0],\n       [    2,   208,     6, ...,     0,     0,     0]], dtype=int32)>)\n1\n(<tf.Tensor: shape=(64, 700), dtype=int32, numpy=\narray([[17415,   368,    10, ...,     0,     0,     0],\n       [ 3199,    14,     4, ...,     0,     0,     0],\n       [  289,    27,    23, ...,     0,     0,     0],\n       ...,\n       [  957,    12,     5, ...,     0,     0,     0],\n       [ 5652,   804,  1004, ...,     0,     0,     0],\n       [  145,     3,    98, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(64, 160), dtype=int32, numpy=\narray([[    2, 10423,     8, ...,     0,     0,     0],\n       [    2,   340,    19, ...,     0,     0,     0],\n       [    2,   238,     8, ...,     0,     0,     0],\n       ...,\n       [    2,    78,     6, ...,     0,     0,     0],\n       [    2,  2713,    19, ...,     0,     0,     0],\n       [    2,  1027,    89, ...,     0,     0,     0]], dtype=int32)>)\n2\n(<tf.Tensor: shape=(64, 700), dtype=int32, numpy=\narray([[ 289,  204,  155, ...,    0,    0,    0],\n       [1023, 2805,   42, ...,    0,    0,    0],\n       [ 675,   20,  821, ...,    0,    0,    0],\n       ...,\n       [ 780,   97,  946, ...,    0,    0,    0],\n       [ 492,   97, 2963, ...,    0,    0,    0],\n       [ 652,   45,    6, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(64, 160), dtype=int32, numpy=\narray([[   2,  238,   19, ...,    0,    0,    0],\n       [   2,  260,    8, ...,    0,    0,    0],\n       [   2, 1492,  142, ...,    0,    0,    0],\n       ...,\n       [   2,   11,    5, ...,    0,    0,    0],\n       [   2, 2017,    8, ...,    0,    0,    0],\n       [   2,  691,    8, ...,    0,    0,    0]], dtype=int32)>)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Encoding"
      ],
      "metadata": {
        "id": "sdqPgwVv2ejQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.532746Z",
          "iopub.execute_input": "2024-12-04T10:34:00.533475Z",
          "iopub.status.idle": "2024-12-04T10:34:00.537902Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.533429Z",
          "shell.execute_reply": "2024-12-04T10:34:00.537081Z"
        },
        "id": "CeaQe1_X2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    position = np.arange(position)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "    exponent = (2 * (i // 2)) / np.float32(d_model)\n",
        "    angle_rates = 1 / np.power(10000, exponent)\n",
        "    angle_rads = position * angle_rates\n",
        "    angle_rads[:, ::2] = np.sin(angle_rads[:, ::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = np.expand_dims(angle_rads, axis=0)\n",
        "    pos_encoding = tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    return pos_encoding"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.539055Z",
          "iopub.execute_input": "2024-12-04T10:34:00.539429Z",
          "iopub.status.idle": "2024-12-04T10:34:00.549358Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.539380Z",
          "shell.execute_reply": "2024-12-04T10:34:00.548597Z"
        },
        "id": "8I8Vum2R2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "    padding_mask = tf.math.equal(seq, 0)\n",
        "    padding_mask = tf.cast(padding_mask, tf.float32)\n",
        "\n",
        "    padding_mask = tf.expand_dims(padding_mask, axis=1)\n",
        "    padding_mask = tf.expand_dims(padding_mask, axis=2)\n",
        "    return padding_mask\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    ones = tf.ones((size, size))\n",
        "\n",
        "    req_matrix = tf.linalg.band_part(ones, -1, 0)\n",
        "    toggle_req_matrix = 1 - req_matrix\n",
        "    mask = toggle_req_matrix\n",
        "    return mask"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.550485Z",
          "iopub.execute_input": "2024-12-04T10:34:00.551214Z",
          "iopub.status.idle": "2024-12-04T10:34:00.559913Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.551184Z",
          "shell.execute_reply": "2024-12-04T10:34:00.559164Z"
        },
        "id": "Q9fgDDle2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaled Dot Product"
      ],
      "metadata": {
        "id": "iN__5_z_2ejQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled, axis=-1)\n",
        "\n",
        "    values = tf.matmul(attention_weights, v)\n",
        "    return values, attention_weights"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.561012Z",
          "iopub.execute_input": "2024-12-04T10:34:00.561371Z",
          "iopub.status.idle": "2024-12-04T10:34:00.573030Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.561333Z",
          "shell.execute_reply": "2024-12-04T10:34:00.572299Z"
        },
        "id": "DK9Fa4rs2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multihead Attention"
      ],
      "metadata": {
        "id": "aYs_9_Ev2ejQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.head_dim = d_model // self.num_heads\n",
        "\n",
        "        self.wq = Dense(d_model)\n",
        "        self.wk = Dense(d_model)\n",
        "        self.wv = Dense(d_model)\n",
        "\n",
        "        self.linear_dense = Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.head_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, q, k, v, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        values, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "\n",
        "        values = tf.transpose(values, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_values = tf.reshape(values, (batch_size, -1, self.d_model))\n",
        "        output = self.linear_dense(concat_values)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.574027Z",
          "iopub.execute_input": "2024-12-04T10:34:00.574292Z",
          "iopub.status.idle": "2024-12-04T10:34:00.586735Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.574266Z",
          "shell.execute_reply": "2024-12-04T10:34:00.586006Z"
        },
        "id": "fEvvPmCD2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feed Forward Network"
      ],
      "metadata": {
        "id": "TisyVi1T2ejQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, hidden):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(hidden, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.587528Z",
          "iopub.execute_input": "2024-12-04T10:34:00.587770Z",
          "iopub.status.idle": "2024-12-04T10:34:00.601527Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.587743Z",
          "shell.execute_reply": "2024-12-04T10:34:00.600699Z"
        },
        "id": "II4LPp3K2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class PointwiseFeedForward(Layer):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PointwiseFeedForward, self).__init__()\n",
        "        self.linear1 = Dense(hidden, activation='relu')\n",
        "        self.linear2 = Dense(d_model)\n",
        "        self.dropout = Dropout(rate=drop_prob)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.602495Z",
          "iopub.execute_input": "2024-12-04T10:34:00.602738Z",
          "iopub.status.idle": "2024-12-04T10:34:00.612812Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.602712Z",
          "shell.execute_reply": "2024-12-04T10:34:00.612165Z"
        },
        "id": "kGdpmBqy2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder layer"
      ],
      "metadata": {
        "id": "CPhbtzSY2ejQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, d_model, num_heads, hidden, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate=rate)\n",
        "\n",
        "        self.ffn = PointwiseFeedForward(d_model, hidden, drop_prob=rate)\n",
        "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout2 = Dropout(rate=rate)\n",
        "\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        residual_x = tf.identity(x)\n",
        "        x, _ = self.attention(x, x, x, mask)\n",
        "        x = self.dropout1(x, training=training)\n",
        "        x = self.norm1(residual_x + x)\n",
        "        residual_x = tf.identity(x)\n",
        "\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout2(x, training=training)\n",
        "        x = self.norm2(residual_x + x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.613770Z",
          "iopub.execute_input": "2024-12-04T10:34:00.614012Z",
          "iopub.status.idle": "2024-12-04T10:34:00.627651Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.613987Z",
          "shell.execute_reply": "2024-12-04T10:34:00.626793Z"
        },
        "id": "_LR-3w5b2ejQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder layer"
      ],
      "metadata": {
        "id": "23u9wGPy2ejR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(Layer):\n",
        "    def __init__(self, d_model, num_heads, hidden, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.attention1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.attention2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = PointwiseFeedForward(d_model, hidden, drop_prob=rate)\n",
        "\n",
        "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.norm3 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(rate=rate)\n",
        "        self.dropout2 = Dropout(rate=rate)\n",
        "        self.dropout3 = Dropout(rate=rate)\n",
        "\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        output1, attention_weights1 = self.attention1(x, x, x, look_ahead_mask)\n",
        "        output1 = self.dropout1(output1, training=training)\n",
        "        output1 = self.norm1(output1 + x)\n",
        "\n",
        "        output2, attention_weights2 = self.attention2(output1, enc_output, enc_output,  padding_mask)\n",
        "        output2 = self.dropout2(output2, training=training)\n",
        "        output2 = self.norm2(output2 + output1)\n",
        "\n",
        "        output3 = self.ffn(output2)\n",
        "        output3 = self.dropout3(output3, training=training)\n",
        "        output3 = self.norm3(output3 + output2)\n",
        "\n",
        "        return output3, attention_weights1, attention_weights2"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.628683Z",
          "iopub.execute_input": "2024-12-04T10:34:00.629009Z",
          "iopub.status.idle": "2024-12-04T10:34:00.640968Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.628972Z",
          "shell.execute_reply": "2024-12-04T10:34:00.640144Z"
        },
        "id": "xFFt_JVz2ejR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(self,  d_model, num_layers, num_heads, hidden, input_vocab_size, max_pos_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(max_pos_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, hidden, rate) for _ in range(num_layers)]\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.642095Z",
          "iopub.execute_input": "2024-12-04T10:34:00.642457Z",
          "iopub.status.idle": "2024-12-04T10:34:00.657174Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.642417Z",
          "shell.execute_reply": "2024-12-04T10:34:00.656331Z"
        },
        "id": "IQwArT5C2ejR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "    def __init__(self, d_model, num_layers,  num_heads, hidden, target_vocab_size, max_pos_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(max_pos_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, hidden, rate) for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training=training,look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
        "\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        return x, attention_weights"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.658362Z",
          "iopub.execute_input": "2024-12-04T10:34:00.658714Z",
          "iopub.status.idle": "2024-12-04T10:34:00.672452Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.658675Z",
          "shell.execute_reply": "2024-12-04T10:34:00.671730Z"
        },
        "id": "erF-T9E-2ejR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(Model):\n",
        "    def __init__(self, d_model, num_layers, num_heads, hidden, input_vocab_size, target_vocab_size, max_pos_input, max_pos_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(d_model, num_layers, num_heads, hidden, input_vocab_size, max_pos_input, rate)\n",
        "        self.decoder = Decoder(d_model, num_layers, num_heads, hidden, target_vocab_size, max_pos_target, rate)\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training=training, mask=enc_padding_mask)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar,\n",
        "            enc_output,\n",
        "            training=training,\n",
        "            look_ahead_mask=look_ahead_mask,\n",
        "            padding_mask=dec_padding_mask\n",
        "        )\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.673515Z",
          "iopub.execute_input": "2024-12-04T10:34:00.673905Z",
          "iopub.status.idle": "2024-12-04T10:34:00.688338Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.673867Z",
          "shell.execute_reply": "2024-12-04T10:34:00.687532Z"
        },
        "id": "6R-0NhtV2ejR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "hidden = 512\n",
        "num_heads = 8\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.692457Z",
          "iopub.execute_input": "2024-12-04T10:34:00.692708Z",
          "iopub.status.idle": "2024-12-04T10:34:00.703181Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.692683Z",
          "shell.execute_reply": "2024-12-04T10:34:00.702471Z"
        },
        "id": "ISrOOB-R2ejR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step* (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.704400Z",
          "iopub.execute_input": "2024-12-04T10:34:00.705054Z",
          "iopub.status.idle": "2024-12-04T10:34:00.715013Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.705012Z",
          "shell.execute_reply": "2024-12-04T10:34:00.714320Z"
        },
        "id": "T9mUnKPy2ejR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.716140Z",
          "iopub.execute_input": "2024-12-04T10:34:00.716471Z",
          "iopub.status.idle": "2024-12-04T10:34:00.729703Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.716432Z",
          "shell.execute_reply": "2024-12-04T10:34:00.728937Z"
        },
        "id": "Mb9_98og2ejR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.730500Z",
          "iopub.execute_input": "2024-12-04T10:34:00.730763Z",
          "iopub.status.idle": "2024-12-04T10:34:00.737701Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.730736Z",
          "shell.execute_reply": "2024-12-04T10:34:00.736915Z"
        },
        "id": "YNZee0LT2ejV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.738538Z",
          "iopub.execute_input": "2024-12-04T10:34:00.738755Z",
          "iopub.status.idle": "2024-12-04T10:34:00.747388Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.738732Z",
          "shell.execute_reply": "2024-12-04T10:34:00.746665Z"
        },
        "id": "s_RGwfHl2ejV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.748134Z",
          "iopub.execute_input": "2024-12-04T10:34:00.748386Z",
          "iopub.status.idle": "2024-12-04T10:34:00.758894Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.748360Z",
          "shell.execute_reply": "2024-12-04T10:34:00.758239Z"
        },
        "id": "Jzxd_ZC92ejV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    d_model,\n",
        "    num_layers,\n",
        "    num_heads,\n",
        "    hidden,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    max_pos_input=encoder_vocab_size,\n",
        "    max_pos_target=decoder_vocab_size,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:00.759980Z",
          "iopub.execute_input": "2024-12-04T10:34:00.760336Z",
          "iopub.status.idle": "2024-12-04T10:34:01.117503Z",
          "shell.execute_reply.started": "2024-12-04T10:34:00.760297Z",
          "shell.execute_reply": "2024-12-04T10:34:01.116524Z"
        },
        "id": "zNx2m5jg2ejV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inputs, targets):\n",
        "    enc_padding_mask = create_padding_mask(inputs)\n",
        "    dec_padding_mask = create_padding_mask(inputs)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(targets)[1])\n",
        "\n",
        "    dec_target_padding_mask = create_padding_mask(targets)\n",
        "\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:01.118577Z",
          "iopub.execute_input": "2024-12-04T10:34:01.118823Z",
          "iopub.status.idle": "2024-12-04T10:34:01.123574Z",
          "shell.execute_reply.started": "2024-12-04T10:34:01.118798Z",
          "shell.execute_reply": "2024-12-04T10:34:01.122705Z"
        },
        "id": "DGt-xTGE2ejV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print('Latest checkpoint restored!')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:01.124545Z",
          "iopub.execute_input": "2024-12-04T10:34:01.124822Z",
          "iopub.status.idle": "2024-12-04T10:34:01.150488Z",
          "shell.execute_reply.started": "2024-12-04T10:34:01.124795Z",
          "shell.execute_reply": "2024-12-04T10:34:01.149693Z"
        },
        "id": "0caiWpLV2ejV",
        "outputId": "532dfd78-2f93-4914-ff7b-b15b3ea2b01e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Latest checkpoint restored!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp,\n",
        "            tar_inp,\n",
        "            training=True,\n",
        "            enc_padding_mask=enc_padding_mask,\n",
        "            look_ahead_mask=combined_mask,\n",
        "            dec_padding_mask=dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:01.151653Z",
          "iopub.execute_input": "2024-12-04T10:34:01.151911Z",
          "iopub.status.idle": "2024-12-04T10:34:01.307196Z",
          "shell.execute_reply.started": "2024-12-04T10:34:01.151884Z",
          "shell.execute_reply": "2024-12-04T10:34:01.306358Z"
        },
        "id": "zdwO0zKp2ejV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_state()\n",
        "    count = 0\n",
        "    for (batch, (inp, tar)) in enumerate(ds):\n",
        "        train_step(inp, tar)\n",
        "        if batch % 429 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "\n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:34:01.309870Z",
          "iopub.execute_input": "2024-12-04T10:34:01.310174Z",
          "iopub.status.idle": "2024-12-04T10:57:38.418119Z",
          "shell.execute_reply.started": "2024-12-04T10:34:01.310146Z",
          "shell.execute_reply": "2024-12-04T10:57:38.417327Z"
        },
        "id": "Bvi7Xo8g2ejV",
        "outputId": "05c28dff-44a8-464b-a2b4-d55361835dd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['embeddings', 'embeddings', 'kernel'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 Batch 0 Loss 9.5986\nEpoch 1 Loss 7.0358\nTime taken for 1 epoch: 171.7232985496521 secs\n\nEpoch 2 Batch 0 Loss 6.7087\nEpoch 2 Loss 6.2426\nTime taken for 1 epoch: 138.20018768310547 secs\n\nEpoch 3 Batch 0 Loss 5.8198\nEpoch 3 Loss 5.5727\nTime taken for 1 epoch: 138.19334769248962 secs\n\nEpoch 4 Batch 0 Loss 5.1906\nEpoch 4 Loss 5.2870\nTime taken for 1 epoch: 138.19213342666626 secs\n\nEpoch 5 Batch 0 Loss 4.9891\nSaving checkpoint for epoch 5 at checkpoints/ckpt-3\nEpoch 5 Loss 5.0799\nTime taken for 1 epoch: 139.00749444961548 secs\n\nEpoch 6 Batch 0 Loss 4.9618\nEpoch 6 Loss 4.8891\nTime taken for 1 epoch: 138.19578433036804 secs\n\nEpoch 7 Batch 0 Loss 4.7513\nEpoch 8 Loss 4.5300\nTime taken for 1 epoch: 138.19642066955566 secs\n\nEpoch 9 Batch 0 Loss 4.4462\nEpoch 9 Loss 4.3510\nTime taken for 1 epoch: 138.18839716911316 secs\n\nEpoch 10 Batch 0 Loss 4.0235\nSaving checkpoint for epoch 10 at checkpoints/ckpt-4\nEpoch 10 Loss 4.1787\nTime taken for 1 epoch: 138.99944972991943 secs\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def evaluate(input_news):\n",
        "    input_news = dia_tokenizer.texts_to_sequences([input_news])\n",
        "    input_news = tf.keras.preprocessing.sequence.pad_sequences(input_news, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_news[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index['<start>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(decoder_maxlen):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            training=False,\n",
        "            enc_padding_mask=enc_padding_mask,\n",
        "            look_ahead_mask=combined_mask,\n",
        "            dec_padding_mask=dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[:, -1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index['<end>']:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:57:38.419068Z",
          "iopub.execute_input": "2024-12-04T10:57:38.419343Z",
          "iopub.status.idle": "2024-12-04T10:57:38.426704Z",
          "shell.execute_reply.started": "2024-12-04T10:57:38.419316Z",
          "shell.execute_reply": "2024-12-04T10:57:38.425805Z"
        },
        "id": "lap-Pism2ejW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input_news):\n",
        "    summarized = evaluate(input_news=input_news)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)\n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:57:38.427733Z",
          "iopub.execute_input": "2024-12-04T10:57:38.427973Z",
          "iopub.status.idle": "2024-12-04T10:57:38.441087Z",
          "shell.execute_reply.started": "2024-12-04T10:57:38.427948Z",
          "shell.execute_reply": "2024-12-04T10:57:38.440473Z"
        },
        "id": "WgHlpK_l2ejW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['id'])\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:57:38.442038Z",
          "iopub.execute_input": "2024-12-04T10:57:38.442279Z",
          "iopub.status.idle": "2024-12-04T10:57:38.460458Z",
          "shell.execute_reply.started": "2024-12-04T10:57:38.442254Z",
          "shell.execute_reply": "2024-12-04T10:57:38.459737Z"
        },
        "id": "QhTkbuNA2ejW",
        "outputId": "021b68a1-0de8-45bf-f630-30433d736715"
      },
      "outputs": [
        {
          "execution_count": 170,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                            dialogue  \\\n0  Amanda: I baked  cookies. Do you want some?\\r\\...   \n1  Olivia: Who are you voting for in this electio...   \n2  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n3  Edward: Rachel, I think I'm in ove with Bella....   \n4  Sam: hey  overheard rick say something\\r\\nSam:...   \n\n                                             summary  \n0  Amanda baked cookies and will bring Jerry some...  \n1  Olivia and Olivier are voting for liberals in ...  \n2  Kim may try the pomodoro technique recommended...  \n3  Edward thinks he is in love with Bella. Rachel...  \n4  Sam is confused, because he overheard Rick com...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialogue</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n      <td>Amanda baked cookies and will bring Jerry some...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Olivia: Who are you voting for in this electio...</td>\n      <td>Olivia and Olivier are voting for liberals in ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n      <td>Kim may try the pomodoro technique recommended...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n      <td>Edward thinks he is in love with Bella. Rachel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n      <td>Sam is confused, because he overheard Rick com...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def checkinbulk(randomnumber):\n",
        "    print('predicted summary:', summarize(df.iloc[randomnumber]['dialogue']))\n",
        "    print('News: ', df.iloc[randomnumber]['dialogue'])\n",
        "    print('Actual summary: ', summary[randomnumber][7:-6])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:57:38.461297Z",
          "iopub.execute_input": "2024-12-04T10:57:38.461510Z",
          "iopub.status.idle": "2024-12-04T10:57:38.469688Z",
          "shell.execute_reply.started": "2024-12-04T10:57:38.461486Z",
          "shell.execute_reply": "2024-12-04T10:57:38.468867Z"
        },
        "id": "xUAVrkOy2ejW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_number = random.randint(0, 1000)\n",
        "\n",
        "checkinbulk(random_number)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-04T10:57:38.470611Z",
          "iopub.execute_input": "2024-12-04T10:57:38.470847Z",
          "iopub.status.idle": "2024-12-04T10:57:42.217919Z",
          "shell.execute_reply.started": "2024-12-04T10:57:38.470822Z",
          "shell.execute_reply": "2024-12-04T10:57:42.217174Z"
        },
        "id": "UTz3pyvT2ejW",
        "outputId": "fcb8fe61-79f7-4cae-9e1e-3d13b2c2e323"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "predicted summary: the team is looking for a new job in the end of the month the year old company is going to be held in august\nNews:  John: <file_other>\nJohn: this blog is awesome\nEwan: I know this one\nJohn: <file_other>\nJohn: thats the trip I want to do next year\nEwan: man you need like 3 weeks of holidays :)\nJohn: I can just quit this shitty job ;)\nEwan: <file_other>\nEwan: check out this one\nEwan: the guy is obsessed with the world's most remote islands\nEwan: he's been on south pacific, indian ocean\nEwan: and now waiting for a ship to tristan da cunha\nJohn: I saw a documentary about it on tv\nJohn: amazing place, no escape from there\nEwan: and no chance to find you once you get there ;)\nActual summary:   John wants to go on a trip next year. He and Ewan are following a blog of a person who travels to remote islands.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "gGIhv30t2ejW"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}